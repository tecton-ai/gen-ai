{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge ...\n",
    "\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/tecton-ai/gen-ai/blob/main/restaurant-recommender/knowledge.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" width=\"150\"/>\n",
    "</a>\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (0.1.21)\n",
      "Requirement already satisfied: llama-index-llms-openai in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (0.2.0)\n",
      "Requirement already satisfied: tecton-gen-ai[langchain,llama-index,tecton] in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (0.0.1b3)\n",
      "Requirement already satisfied: typing-extensions>=4.5 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton-gen-ai[langchain,llama-index,tecton]) (4.12.2)\n",
      "Requirement already satisfied: pandas!=2.2.2 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton-gen-ai[langchain,llama-index,tecton]) (2.2.1)\n",
      "Requirement already satisfied: tecton~=1.0.0rc3 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.0.0)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton-gen-ai[langchain,llama-index,tecton]) (0.2.13)\n",
      "Requirement already satisfied: langchain-community in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton-gen-ai[langchain,llama-index,tecton]) (0.2.12)\n",
      "Requirement already satisfied: langchain-core in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton-gen-ai[langchain,llama-index,tecton]) (0.2.30)\n",
      "Requirement already satisfied: llama-index in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton-gen-ai[langchain,llama-index,tecton]) (0.11.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain-openai) (1.40.6)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-llms-openai) (0.11.0.post1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (0.1.99)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (2.9.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (8.5.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2024.9.0)\n",
      "Requirement already satisfied: httpx in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2.32.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (4.66.5)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.16.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pandas!=2.2.2->tecton-gen-ai[langchain,llama-index,tecton]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pandas!=2.2.2->tecton-gen-ai[langchain,llama-index,tecton]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pandas!=2.2.2->tecton-gen-ai[langchain,llama-index,tecton]) (2024.1)\n",
      "Requirement already satisfied: attrs>=21.3.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (24.2.0)\n",
      "Requirement already satisfied: boto3 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.35.7)\n",
      "Requirement already satisfied: jinja2~=3.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (3.1.4)\n",
      "Requirement already satisfied: pathspec in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (0.12.1)\n",
      "Requirement already satisfied: pendulum~=2.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.1.2)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (5.28.0)\n",
      "Requirement already satisfied: pypika~=0.48.9 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (0.48.9)\n",
      "Requirement already satisfied: pytimeparse in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.1.8)\n",
      "Requirement already satisfied: texttable in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.7.0)\n",
      "Requirement already satisfied: colorama~=0.4 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (0.4.6)\n",
      "Requirement already satisfied: yaspin<3,>=0.16 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.5.0)\n",
      "Requirement already satisfied: pygments>=2.7.4 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.18.0)\n",
      "Requirement already satisfied: pytest in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (8.3.2)\n",
      "Requirement already satisfied: click~=8.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (8.1.7)\n",
      "Requirement already satisfied: typeguard~=2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.13.3)\n",
      "Requirement already satisfied: sqlparse in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (0.5.1)\n",
      "Requirement already satisfied: semantic-version in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.10.0)\n",
      "Requirement already satisfied: pyarrow<16,>=8 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (15.0.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (74.1.2)\n",
      "Requirement already satisfied: pip in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (24.2)\n",
      "Requirement already satisfied: pex~=2.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.17.0)\n",
      "Requirement already satisfied: deltalake>=0.17.4 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (0.18.2)\n",
      "Requirement already satisfied: duckdb==1.0.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.0.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.7.24)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain->tecton-gen-ai[langchain,llama-index,tecton]) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain->tecton-gen-ai[langchain,llama-index,tecton]) (0.2.2)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.3.0)\n",
      "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.3.0)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.2.3)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.3.0)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.9.48.post3)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.2.0)\n",
      "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.2.0)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.2.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.2.0)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.9.11)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.8)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.2.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.21.3)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from deltalake>=0.17.4->tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (0.6)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from jinja2~=3.0->tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.1.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (3.10.7)\n",
      "Requirement already satisfied: llama-cloud>=0.0.11 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.0.15)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.4.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-readers-llama-parse>=0.2.0->llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.5.0)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.4.2)\n",
      "Requirement already satisfied: pytzdata>=2020.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pendulum~=2.1->tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2020.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (2.23.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas!=2.2.2->tecton-gen-ai[langchain,llama-index,tecton]) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.26.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.0.0)\n",
      "Requirement already satisfied: termcolor<3.0,>=2.3 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from yaspin<3,>=0.16->tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.4.0)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.7 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from boto3->tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.35.7)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from boto3->tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from boto3->tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (0.10.2)\n",
      "Requirement already satisfied: iniconfig in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pytest->tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pytest->tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.5.0)\n",
      "Requirement already satisfied: tomli>=1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pytest->tecton~=1.0.0rc3->tecton[rift]~=1.0.0rc3; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'tecton-gen-ai[tecton,langchain,llama-index]' langchain-openai llama-index-llms-openai "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Set the enviroment in development mode. This allows you to run the notebook locally without the need to logon to the Tecton Platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tecton_gen_ai.testing import set_dev_mode\n",
    "\n",
    "set_dev_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "review_data = pd.DataFrame([\n",
    "  {\n",
    "    \"user_id\": \"user1\",\n",
    "    \"restaurant_name\": \"The Capital Grille\",\n",
    "    \"rating\": 5,\n",
    "    \"review_text\": \"Exceptional dining experience! The aged steaks are out of this world. Impeccable service and ambiance. Perfect for special occasions.\",\n",
    "    \"timestamp\": \"2024-07-15T19:30:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user1\",\n",
    "    \"restaurant_name\": \"Firebirds Wood Fired Grill\",\n",
    "    \"rating\": 4,\n",
    "    \"review_text\": \"Great spot for grilled meats. The wood-fired flavor really comes through in every dish. Solid cocktail selection too.\",\n",
    "    \"timestamp\": \"2024-07-22T18:45:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user1\",\n",
    "    \"restaurant_name\": \"The Capital Grille\",\n",
    "    \"rating\": 3,\n",
    "    \"review_text\": \"Decent experience, but not as impressive as expected for the price. Steak was good, but sides were underwhelming. Service was attentive.\",\n",
    "    \"timestamp\": \"2024-07-30T20:15:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user1\",\n",
    "    \"restaurant_name\": \"Firebirds Wood Fired Grill\",\n",
    "    \"rating\": 5,\n",
    "    \"review_text\": \"Absolutely love this place! The wood-grilled salmon was perfectly cooked. Great atmosphere for a date night or family dinner.\",\n",
    "    \"timestamp\": \"2024-08-05T19:00:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user1\",\n",
    "    \"restaurant_name\": \"The Capital Grille\",\n",
    "    \"rating\": 2,\n",
    "    \"review_text\": \"Disappointing visit. The steak was overcooked, and the sides were bland. Expected much more for the price point. Service was good though.\",\n",
    "    \"timestamp\": \"2024-08-12T20:30:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user1\",\n",
    "    \"restaurant_name\": \"Firebirds Wood Fired Grill\",\n",
    "    \"rating\": 4,\n",
    "    \"review_text\": \"Consistently good food and service. The wood-fired grill adds a nice touch to everything. Their burgers are especially tasty.\",\n",
    "    \"timestamp\": \"2024-08-19T18:30:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user1\",\n",
    "    \"restaurant_name\": \"Viva Chicken\",\n",
    "    \"rating\": 3,\n",
    "    \"review_text\": \"Decent Peruvian-style chicken, but it can be hit or miss. Sometimes it's a bit dry. Love their sauces though. Good for a quick meal.\",\n",
    "    \"timestamp\": \"2024-08-26T12:45:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user2\",\n",
    "    \"restaurant_name\": \"Mama Ricotta's\",\n",
    "    \"rating\": 5,\n",
    "    \"review_text\": \"Incredible Italian cuisine! The pasta was cooked to perfection and the sauce was divine. Excellent service too. Feels like a slice of Italy.\",\n",
    "    \"timestamp\": \"2024-07-18T19:15:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user2\",\n",
    "    \"restaurant_name\": \"Villa Antonio\",\n",
    "    \"rating\": 4,\n",
    "    \"review_text\": \"Charming Italian restaurant with great pasta dishes. The ambiance is romantic and the wine list is impressive. The tiramisu is a must-try!\",\n",
    "    \"timestamp\": \"2024-07-25T20:00:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user2\",\n",
    "    \"restaurant_name\": \"Mama Ricotta's\",\n",
    "    \"rating\": 3,\n",
    "    \"review_text\": \"Okay Italian food, but I've had better. Portions are generous, which is a plus. Service was friendly. Decent spot for a casual dinner.\",\n",
    "    \"timestamp\": \"2024-08-02T18:30:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user2\",\n",
    "    \"restaurant_name\": \"Villa Antonio\",\n",
    "    \"rating\": 5,\n",
    "    \"review_text\": \"Authentic Italian flavors that transport you to Italy! The homemade pasta is outstanding. Cozy atmosphere perfect for a romantic dinner.\",\n",
    "    \"timestamp\": \"2024-08-09T19:45:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user2\",\n",
    "    \"restaurant_name\": \"Mama Ricotta's\",\n",
    "    \"rating\": 4,\n",
    "    \"review_text\": \"Cozy Italian spot with delicious homemade pasta. The garlic bread is addictive! A bit noisy on weekends, but the food makes up for it.\",\n",
    "    \"timestamp\": \"2024-08-16T20:15:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user2\",\n",
    "    \"restaurant_name\": \"Villa Antonio\",\n",
    "    \"rating\": 2,\n",
    "    \"review_text\": \"Underwhelming experience. The pasta was overcooked and the sauce lacked flavor. Service was slow. Not up to par with other Italian restaurants in the area.\",\n",
    "    \"timestamp\": \"2024-08-23T19:30:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user3\",\n",
    "    \"restaurant_name\": \"Wan Fu\",\n",
    "    \"rating\": 4,\n",
    "    \"review_text\": \"Surprisingly good Chinese food. Fresh ingredients and tasty dishes. A step above typical Chinese takeout. The kung pao chicken was excellent.\",\n",
    "    \"timestamp\": \"2024-07-20T18:00:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user3\",\n",
    "    \"restaurant_name\": \"Ru San's\",\n",
    "    \"rating\": 5,\n",
    "    \"review_text\": \"Sushi paradise! Wide variety of rolls and always fresh fish. The all-you-can-eat option is a great deal. Friendly and efficient service.\",\n",
    "    \"timestamp\": \"2024-07-28T19:30:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user3\",\n",
    "    \"restaurant_name\": \"Wan Fu Quality Chinese Cuisine\",\n",
    "    \"rating\": 3,\n",
    "    \"review_text\": \"Decent Chinese restaurant. Nothing special, but nothing terrible either. The hot and sour soup was good. Quick delivery is a plus.\",\n",
    "    \"timestamp\": \"2024-08-04T20:00:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user3\",\n",
    "    \"restaurant_name\": \"Ru San's\",\n",
    "    \"rating\": 4,\n",
    "    \"review_text\": \"Consistently good sushi at reasonable prices. The specialty rolls are creative and tasty. Nice ambiance for casual dining with friends.\",\n",
    "    \"timestamp\": \"2024-08-11T18:45:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user3\",\n",
    "    \"restaurant_name\": \"Wan Fu\",\n",
    "    \"rating\": 2,\n",
    "    \"review_text\": \"Disappointing Chinese food. Seemed reheated and lacked authentic flavors. The dumplings were good, but everything else was mediocre. Service was quick though.\",\n",
    "    \"timestamp\": \"2024-08-18T19:15:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user3\",\n",
    "    \"restaurant_name\": \"Wan Fu Quality Chinese Cuisine\",\n",
    "    \"rating\": 5,\n",
    "    \"review_text\": \"Best Chinese food I've had in the area! The flavors are authentic and everything tastes freshly made. Generous portions too. Highly recommend the Szechuan dishes.\",\n",
    "    \"timestamp\": \"2024-08-25T20:30:00Z\"\n",
    "  },\n",
    "  {\n",
    "    \"user_id\": \"user3\",\n",
    "    \"restaurant_name\": \"Ru San's\",\n",
    "    \"rating\": 3,\n",
    "    \"review_text\": \"Average sushi experience. Fish was fresh, but the rolls were a bit loose. Decent variety on the menu. Service was friendly but slow during peak hours.\",\n",
    "    \"timestamp\": \"2024-09-01T19:00:00Z\"\n",
    "  }\n",
    "]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tecton_gen_ai.fco import AgentClient, AgentService, prompt\n",
    "from tecton_gen_ai.testing import make_local_source\n",
    "from tecton_gen_ai.utils.tecton_utils import make_request_source\n",
    "from tecton_gen_ai.testing.utils import make_local_vector_db_config\n",
    "from tecton_gen_ai.fco import source_as_knowledge\n",
    "\n",
    "\n",
    "location_request = make_request_source(location = str)\n",
    "    \n",
    "@prompt(sources=[ location_request])\n",
    "def sys_prompt(location_request ):\n",
    "    location = location_request[\"location\"]\n",
    "    return f\"\"\"\n",
    "    You are a consierge service that recommends restaurants.\n",
    "    Provide an address for the restaurant.\n",
    "    Provide suggested menu items.\n",
    "    Only suggest restaurants that are in or near {location}. \n",
    "    \"\"\"\n",
    "\n",
    "#provide a vector db config\n",
    "conf = make_local_vector_db_config(\"/tmp/test.db\", remove_if_exists=True)\n",
    "\n",
    "#create embeddings of the restaurant descriptions in the vector DB\n",
    "src = make_local_source(\"reviews\", review_data, \n",
    "                         auto_timestamp=True, description=\"Restaurant reviews\")\n",
    "\n",
    "restaurant_reviews = source_as_knowledge(\n",
    "    src,\n",
    "    vector_db_config=conf,\n",
    "    vectorize_column=\"review_text\",\n",
    "    filter = [(\"restaurant_name\", str, \"the name of the restaurant\")]\n",
    ")\n",
    "\n",
    "service = AgentService(\n",
    "    name=\"restaurant_recommender\",\n",
    "    knowledge=[restaurant_reviews],\n",
    "    prompts=[sys_prompt]\n",
    ")\n",
    "\n",
    "client = AgentClient.from_local(service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# instantiate LLM model for  LangChain \n",
    "langchain_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# create invocable agent for LangChain \n",
    "langchain_agent = client.make_agent(langchain_llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I recommend checking out **The Capital Grille** for dinner. It has received exceptional reviews for its aged steaks, with one user praising it as \"out of this world,\" along with impeccable service and ambiance, making it perfect for special occasions. \n",
      "\n",
      "Another option is **Firebirds Wood Fired Grill**, which is known for its great grilled meats and has a solid cocktail selection. While it may not specifically highlight aged steaks, it offers a great dining experience overall.\n",
      "\n",
      "Both places seem to offer a great atmosphere for dinner!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with client.set_context({\"user_id\": \"user1\", \"location\":\"Charlotte, NC\"}):\n",
    "    print(langchain_agent.invoke({\"input\":\"recommend a restaurant for dinner that has aged steaks\"})[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some restaurant recommendations that have received feedback for great food but bad service:\n",
      "\n",
      "1. **Wan Fu**\n",
      "   - **Rating:** 2/5\n",
      "   - **Review:** Disappointing Chinese food. Seemed reheated and lacked authentic flavors. The dumplings were good, but everything else was mediocre. Service was quick though.\n",
      "\n",
      "2. **The Capital Grille**\n",
      "   - **Rating:** 2/5\n",
      "   - **Review:** Disappointing visit. The steak was overcooked, and the sides were bland. Expected much more for the price point. Service was good though.\n",
      "\n",
      "3. **Villa Antonio**\n",
      "   - **Rating:** 2/5\n",
      "   - **Review:** Underwhelming experience. The pasta was overcooked and the sauce lacked flavor. Service was slow. Not up to par with other Italian restaurants in the area.\n",
      "\n",
      "These restaurants might fit your criteria for having great food but poor service.\n"
     ]
    }
   ],
   "source": [
    "with client.set_context({\"user_id\": \"user3\", \"location\":\"Charlotte, NC\"}):\n",
    "    print(langchain_agent.invoke({\"input\":\"recommend a restaurant for dinner that has great food but bad service\"})[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Summary of Reviews for The Capital Grille\n",
      "\n",
      "- **Average Rating:** 3.33\n",
      "\n",
      "#### Best Review:\n",
      "- **Rating:** 5\n",
      "- **Review Text:** \"Exceptional dining experience! The aged steaks are out of this world. Impeccable service and ambiance. Perfect for special occasions.\"\n",
      "- **Timestamp:** July 15, 2024\n",
      "\n",
      "#### Worst Review:\n",
      "- **Rating:** 2\n",
      "- **Review Text:** \"Disappointing visit. The steak was overcooked, and the sides were bland. Expected much more for the price point. Service was good though.\"\n",
      "- **Timestamp:** August 12, 2024\n",
      "\n",
      "Overall, The Capital Grille has received mixed reviews, with some diners praising the exceptional dining experience and others expressing disappointment in the quality of the food relative to its price.\n"
     ]
    }
   ],
   "source": [
    "with client.set_context({\"user_id\": \"user3\", \"location\":\"Charlotte, NC\"}):\n",
    "    print(langchain_agent.invoke({\"input\":\"summarize reviews for The Capital Grille, provide the average rating and worst and best reviews\"})[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tecton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
