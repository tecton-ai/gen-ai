{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Prompts, Features as Tools and Knowledge \n",
    "\n",
    "By combining the Tecton GenAI functions, you can provide much better context in for your LLM applications.\n",
    "- The *knowledge* function provides RAG functionality by taking unstructured text and calculating embedding vectors for them and storing them in a vector database that provides similarity search capabilities to better respond to user queries. \n",
    "- The *prompt* provides instructions for the LLM and is enriched with context from feature pipelines or directly from the real-time context.\n",
    "- *Features as tools* give the LLM the ability to retrieve additional data when it needs it to respond to the user question.\n",
    "\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/tecton-ai/gen-ai/blob/main/knowledge.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" width=\"150\"/>\n",
    "</a>\n",
    "\n",
    "In this notebook, you will combine all three tools to create an example restaurant recommendation chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (0.1.21)\n",
      "Requirement already satisfied: llama-index-llms-openai in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (0.2.0)\n",
      "Collecting tecton-gen-ai[langchain,llama-index,tecton]\n",
      "  Using cached tecton_gen_ai-0.0.1b2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton-gen-ai[langchain,llama-index,tecton]) (4.12.2)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton-gen-ai[langchain,llama-index,tecton]) (0.2.13)\n",
      "Requirement already satisfied: langchain-community in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton-gen-ai[langchain,llama-index,tecton]) (0.2.12)\n",
      "Requirement already satisfied: langchain-core in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton-gen-ai[langchain,llama-index,tecton]) (0.2.30)\n",
      "Requirement already satisfied: llama-index in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton-gen-ai[langchain,llama-index,tecton]) (0.11.0)\n",
      "Requirement already satisfied: tecton~=1.0.0rc0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.0.0rc1)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain-openai) (1.40.6)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-llms-openai) (0.11.0.post1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (0.1.99)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (2.9.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (8.5.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2024.9.0)\n",
      "Requirement already satisfied: httpx in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2.32.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (4.66.5)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.16.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=21.3.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (24.2.0)\n",
      "Requirement already satisfied: boto3 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.35.7)\n",
      "Requirement already satisfied: jinja2~=3.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (3.1.4)\n",
      "Requirement already satisfied: pathspec in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (0.12.1)\n",
      "Requirement already satisfied: pendulum~=2.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.1.2)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (5.28.0)\n",
      "Requirement already satisfied: pypika~=0.48.9 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (0.48.9)\n",
      "Requirement already satisfied: pytimeparse in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.1.8)\n",
      "Requirement already satisfied: pandas>=1.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.2.2)\n",
      "Requirement already satisfied: texttable in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.7.0)\n",
      "Requirement already satisfied: colorama~=0.4 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (0.4.6)\n",
      "Requirement already satisfied: yaspin<3,>=0.16 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.5.0)\n",
      "Requirement already satisfied: pygments>=2.7.4 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.18.0)\n",
      "Requirement already satisfied: pytest in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (8.3.2)\n",
      "Requirement already satisfied: click~=8.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (8.1.7)\n",
      "Requirement already satisfied: typeguard~=2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.13.3)\n",
      "Requirement already satisfied: sqlparse in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (0.5.1)\n",
      "Requirement already satisfied: semantic-version in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.10.0)\n",
      "Requirement already satisfied: pyarrow<16,>=8 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (15.0.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (74.1.2)\n",
      "Requirement already satisfied: pip in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (24.2)\n",
      "Requirement already satisfied: pex~=2.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.17.0)\n",
      "Requirement already satisfied: deltalake>=0.17.4 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (0.18.2)\n",
      "Requirement already satisfied: duckdb==1.0.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.0.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.7.24)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain->tecton-gen-ai[langchain,llama-index,tecton]) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langchain->tecton-gen-ai[langchain,llama-index,tecton]) (0.2.2)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.3.0)\n",
      "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.3.0)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.2.3)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.3.0)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.9.48.post3)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.2.0)\n",
      "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.2.0)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.2.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.2.0)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.9.11)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.8)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.2.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.21.3)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from deltalake>=0.17.4->tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (0.6)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from jinja2~=3.0->tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.1.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (3.10.7)\n",
      "Requirement already satisfied: llama-cloud>=0.0.11 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.0.15)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.4.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from llama-index-readers-llama-parse>=0.2.0->llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (0.5.0)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pandas>=1.0->tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pandas>=1.0->tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pandas>=1.0->tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2024.1)\n",
      "Requirement already satisfied: pytzdata>=2020.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pendulum~=2.1->tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2020.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core->tecton-gen-ai[langchain,llama-index,tecton]) (2.23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.26.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.0.0)\n",
      "Requirement already satisfied: termcolor<3.0,>=2.3 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from yaspin<3,>=0.16->tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.4.0)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.7 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from boto3->tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.35.7)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from boto3->tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from boto3->tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (0.10.2)\n",
      "Requirement already satisfied: iniconfig in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pytest->tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pytest->tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.5.0)\n",
      "Requirement already satisfied: tomli>=1 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from pytest->tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (2.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index->tecton-gen-ai[langchain,llama-index,tecton]) (2.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/tecton/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.0->tecton~=1.0.0rc0->tecton[rift]~=1.0.0rc0; extra == \"tecton\"->tecton-gen-ai[langchain,llama-index,tecton]) (1.16.0)\n",
      "Using cached tecton_gen_ai-0.0.1b2-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: tecton-gen-ai\n",
      "Successfully installed tecton-gen-ai-0.0.1b2\n"
     ]
    }
   ],
   "source": [
    "!pip install 'tecton-gen-ai[tecton,langchain,llama-index]' langchain-openai llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log in to Tecton\n",
    "Make sure to hit enter after pasting in your authentication token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-authenticating. Switching from https://explore.tecton.ai to explore.tecton.ai\n",
      "Please visit the following link to login and access the authentication code:\n",
      "https://login.tecton.ai/oauth2/default/v1/authorize?response_type=code&client_id=0oazt04n72Fkm3APE357&redirect_uri=https%3A%2F%2Fwww.tecton.ai%2Fauthorization-callback&state=4440501147844737537&scope=openid+offline_access+profile+email&code_challenge_method=S256&code_challenge=SkwAHlYvvB5WpkNgCkcOohlYLB0BGUxv2ZqN1EOz9R8\n",
      "âœ… Authentication successful!\n"
     ]
    }
   ],
   "source": [
    "import tecton\n",
    "\n",
    "tecton.login(\"explore.tecton.ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example you will use an OpenAI gpt-4o LLM model to test. \n",
    "\n",
    "You will need to provide an Open AI API key for this purpose.\n",
    "\n",
    "Replace \"your-openai-key\" with your own key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# replace with your key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Views\n",
    "In the following cell you create two mock feature views:\n",
    "- user_info_fv: provides each user's profile information, including name, age and food_preference. \n",
    "- recent_eats_fv: provides a list of the last three restaurants each user visited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tecton_gen_ai.testing import mock_batch_feature_view\n",
    "\n",
    "\n",
    "# mock user info data\n",
    "user_info = pd.DataFrame(\n",
    "        [\n",
    "            {\"user_id\": \"user1\", \"name\": \"Jim\",  \"age\": 30, \"food_preference\": \"American\"},\n",
    "            {\"user_id\": \"user2\", \"name\": \"John\", \"age\": 40, \"food_preference\": \"Italian\"},\n",
    "            {\"user_id\": \"user3\", \"name\": \"Jane\", \"age\": 50, \"food_preference\": \"Chinese\"},\n",
    "        ]\n",
    "    )\n",
    "user_info_fv = mock_batch_feature_view( \"user_info_fv\", user_info, entity_keys=[\"user_id\"], description=\"User's basic information.\")\n",
    "\n",
    "# mock user's recent visits \n",
    "recent_eats = pd.DataFrame(\n",
    "        [\n",
    "            {\"user_id\": \"user1\", \"last_3_visits\":str([\"Mama Ricotta's\", \"The Capital Grille\", \"Firebirds Wood Fired Grill\"])},\n",
    "            {\"user_id\": \"user2\", \"last_3_visits\":str([\"Mama Ricotta's\", \"Villa Antonio\", \"Viva Chicken\"])},\n",
    "            {\"user_id\": \"user3\", \"last_3_visits\":str([\"Wan Fu\", \"Wan Fu Quality Chinese Cuisine\", \"Ru San's\"])},\n",
    "        ]\n",
    "    )\n",
    "recent_eats_fv = mock_batch_feature_view( \"recent_eats_fv\", recent_eats, entity_keys=[\"user_id\"], description=\"User's recent restaurant visits.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant Descriptions - Source of Knowledge\n",
    "You'll use a sample of restaurants descriptions as a base of knowledge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mock restaurant description data for knowledge\n",
    "restaurant_descriptions = pd.DataFrame([\n",
    "  {\n",
    "    \"name\": \"Mama Ricotta's\",\n",
    "    \"description\": \"A Charlotte staple since 1992, Mama Ricotta's offers authentic Italian cuisine in a warm, family-friendly atmosphere. Known for their hand-tossed pizzas, homemade pasta, and signature chicken parmesan.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"The Capital Grille\",\n",
    "    \"description\": \"An upscale steakhouse chain featuring dry-aged steaks, fresh seafood, and an extensive wine list. The Charlotte location offers a refined dining experience with impeccable service and a sophisticated ambiance.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Firebirds Wood Fired Grill\",\n",
    "    \"description\": \"A polished casual restaurant known for its classic American cuisine cooked over an open wood fire. Specialties include hand-cut steaks, fresh seafood, and signature cocktails in a warm, contemporary setting.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Villa Antonio\",\n",
    "    \"description\": \"An elegant Italian restaurant offering a romantic atmosphere and authentic cuisine. Known for its homemade pasta, extensive wine selection, and attentive service, perfect for special occasions.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Viva Chicken\",\n",
    "    \"description\": \"A fast-casual eatery specializing in Peruvian-style rotisserie chicken. Offers fresh, flavorful dishes with a modern twist on traditional Peruvian cuisine, including quinoa stuffed avocados and yuca fries.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Wan Fu\",\n",
    "    \"description\": \"A local favorite for Chinese cuisine, Wan Fu offers a wide array of traditional and Americanized Chinese dishes. Known for its generous portions, friendly service, and comfortable dining atmosphere.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Wan Fu Quality Chinese Cuisine\",\n",
    "    \"description\": \"An upscale Chinese restaurant focusing on authentic flavors and high-quality ingredients. Offers a more refined dining experience with a menu featuring both classic and innovative Chinese dishes.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Ru San's\",\n",
    "    \"description\": \"A popular sushi restaurant known for its extensive menu and all-you-can-eat option. Offers a wide variety of sushi rolls, sashimi, and other Japanese dishes in a casual, vibrant atmosphere.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Le Bernardin\",\n",
    "    \"description\": \"A world-renowned, Michelin three-star restaurant specializing in exquisite seafood. Chef Eric Ripert's menu features innovative preparations of the finest global seafood in an elegant setting.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Katz's Delicatessen\",\n",
    "    \"description\": \"An iconic New York institution since 1888, famous for its hand-carved pastrami and corned beef sandwiches. The bustling, no-frills atmosphere is part of its enduring charm.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Eleven Madison Park\",\n",
    "    \"description\": \"A three-Michelin-starred restaurant offering an innovative tasting menu focusing on locally sourced, plant-based ingredients. Known for its impeccable service and artistic presentation.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Peter Luger Steak House\",\n",
    "    \"description\": \"A Brooklyn institution since 1887, Peter Luger is famous for its dry-aged steaks and old-school, cash-only policy. The no-frills atmosphere focuses attention on the exceptional quality of the meat.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Di Fara Pizza\",\n",
    "    \"description\": \"A legendary Brooklyn pizzeria, Di Fara is known for its handcrafted pies made by founder Dom DeMarco. Each pizza is a work of art, featuring high-quality ingredients and meticulous preparation.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Balthazar\",\n",
    "    \"description\": \"A SoHo classic, Balthazar offers authentic French brasserie fare in a vibrant, bustling atmosphere. Known for its fresh seafood, classic French dishes, and popular weekend brunch.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Momofuku Ko\",\n",
    "    \"description\": \"Chef David Chang's two-Michelin-starred restaurant offers an ever-changing tasting menu blending Asian and Western influences. The intimate counter seating provides a unique, interactive dining experience.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"The Halal Guys\",\n",
    "    \"description\": \"Starting as a food cart, The Halal Guys has become a New York institution. Famous for its chicken and gyro over rice, topped with their legendary white sauce. Now with brick-and-mortar locations.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Russ & Daughters\",\n",
    "    \"description\": \"A New York classic since 1914, specializing in traditional Jewish appetizing foods. Famous for its hand-sliced smoked salmon, bagels, and other Jewish delicacies. Now includes a sit-down cafe.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Lombardi's\",\n",
    "    \"description\": \"America's first pizzeria, established in 1905. Lombardi's continues to serve classic New York-style pizza from its coal-fired oven. Known for its simple, high-quality ingredients and historic charm.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Joe's Shanghai\",\n",
    "    \"description\": \"Famous for introducing soup dumplings to New York, Joe's Shanghai offers authentic Shanghai-style cuisine. The bustling, no-frills atmosphere adds to the authentic experience.\"\n",
    "  }\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Prompt\n",
    "\n",
    "The following cell creates the prompt for our restaurant recommendation example.\n",
    "\n",
    "- It uses a *request source* to obtain the location directly from the execution context.\n",
    "- It incorporates the user's name into the prompt instructions from the user_info_fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tecton_gen_ai.core_utils import make_request_source\n",
    "from tecton_gen_ai.fco import prompt\n",
    "\n",
    "#define real-time request source\n",
    "location_request = make_request_source(location = str)\n",
    "\n",
    "#create the prompt\n",
    "@prompt(sources=[ location_request, user_info_fv])  # specifies sources of data for the prompt\n",
    "def sys_prompt(location_request, user_info_fv ):\n",
    "    location = location_request[\"location\"]\n",
    "    name = user_info_fv[\"name\"]\n",
    "    return f\"\"\"\n",
    "    Address the user by their name. Their name is {name}.\n",
    "    You are a consierge service that recommends restaurants.\n",
    "    Respond to the user's question. \n",
    "    If the user asks for a restaurant recommendation respond with a specific restaurant that you know and suggested menu items. \n",
    "    Only suggest restaurants that are in or near {location}. \n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Knowledge\n",
    "\n",
    "Allows you to add your unstructured data \n",
    "self select\n",
    "retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tecton_gen_ai.testing import mock_knowledge\n",
    "from tecton_gen_ai.testing.utils import create_testing_vector_db_config\n",
    "#source_as_knowledge instead of mock_knowledge\n",
    "\n",
    "#provide a vector db config\n",
    "conf = create_testing_vector_db_config(\"/tmp/test.db\", remove_if_exists=True)\n",
    "\n",
    "#create embeddings of the restaurant descriptions in the vector DB\n",
    "restaurant_knowledge = mock_knowledge(\n",
    "    \"restaurant_descriptions\",\n",
    "    restaurant_descriptions,\n",
    "    description=\"Restaurant descriptions\",\n",
    "    vector_db_config=conf,\n",
    "    vectorize_column=\"description\",\n",
    "    max_rows=len(restaurant_descriptions),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Service\n",
    "\n",
    "This example agent service, encapsulates the context and information retrieval being made available:\n",
    "- sys_prompt \n",
    "- restaurant_knowledge\n",
    "- user_info_fv & recent_eats_fv feature views\n",
    "\n",
    "In a production application, an Agent Service is deployed to the Tecton Platform to provide prompts, knowledge and data retrieval through features as tools at scale, through Tecton's serving infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tecton_gen_ai.agent import AgentClient, AgentService\n",
    "from tecton_gen_ai.core_utils import make_request_source\n",
    "\n",
    "#define the Tecton Agent Service specifying the prompts, sources of knowledge and feature tools \n",
    "service = AgentService(\n",
    "    name=\"restaurant_recommender\",\n",
    "    prompts=[sys_prompt],\n",
    "    knowledge=[restaurant_knowledge],\n",
    "    tools=[ user_info_fv, recent_eats_fv]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Client\n",
    "In order to interact with the LLM, you can create an Agent Client that interacts with the Agent Service and provides the interface through which the LLM workflow can retrieve the prompts, knowledge and feature data retrieval.\n",
    "\n",
    "The following cell shows an example of this using LangChain and OpenAI's gpt-4o model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#create an agent client that provides context for LLM workflows\n",
    "client = AgentClient.from_local(service)\n",
    "\n",
    "# instantiate LLM model for  LangChain \n",
    "langchain_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# create invokable agent for LangChain \n",
    "langchain_agent = client.make_agent(langchain_llm, system_prompt=\"sys_prompt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "\n",
    "The following test uses the user's id and their current location to respond to the user request.\n",
    "\n",
    "- It uses knowledge to determine which restaurant's descriptions include a romantic or intimate experience.\n",
    "- It uses the user's information to refer to them by name.\n",
    "- It uses the current location of the user to determine which restaurants are in that location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jim, for a romantic dinner in Charlotte, I recommend **Villa Antonio**. It's an elegant Italian restaurant that offers a romantic atmosphere with authentic cuisine. You can indulge in their homemade pasta and enjoy an extensive wine selection. It's perfect for special occasions!\n",
      "\n",
      "If you're looking for menu suggestions, try their **Fettuccine Alfredo** or the **Osso Buco** paired with a nice Chianti. Enjoy your dinner!\n"
     ]
    }
   ],
   "source": [
    "#from tecton_gen_ai.testing.utils import print_md\n",
    "\n",
    "with client.set_context({\"user_id\": \"user1\", \"location\":\"Charlotte, NC\"}):\n",
    "    print(langchain_agent.invoke({\"input\":\"recommend a romantic dinner\"})[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example, for `user2` the LLM uses his name, and their food preference from the user info feature view.\n",
    "\n",
    "It also figures out a restaurant that the user has not been to recently by retrieving that data from a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi John! Since you enjoy Italian cuisine and have recently visited Mama Ricotta's and Villa Antonio, I recommend trying **Di Fara Pizza**. It's a legendary pizzeria known for its handcrafted pies made by founder Dom DeMarco. Each pizza is a work of art, featuring high-quality ingredients and meticulous preparation.\n",
      "\n",
      "You might want to try their classic Margherita pizza or the Di Fara special, which is topped with fresh mozzarella, basil, and a drizzle of olive oil. Enjoy your meal!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with client.set_context({\"user_id\": \"user2\", \"location\":\"Charlotte, NC\"}):\n",
    "    print(langchain_agent.invoke({\"input\":\"Recommend a place I haven't been to before that serves my preference\"})[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the user just refers to a specific chef.\n",
    "The LLM uses the knowledge to find that chef's restaurant and determines that it is not near the user's location but still recommends an option near them which offers a similar cuisine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While Chef Eric Ripert is known for his exceptional seafood cuisine at Le Bernardin in New York City, unfortunately, he doesn't have a restaurant in Ballantyne, Charlotte, NC. However, if you're looking for an exquisite dining experience in your area, I recommend **Mama Ricotta's**. \n",
      "\n",
      "Here are some suggested menu items:\n",
      "- Hand-tossed pizzas\n",
      "- Homemade pasta\n",
      "- Signature chicken parmesan\n",
      "\n",
      "Mama Ricotta's offers a warm, family-friendly atmosphere that you might enjoy!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with client.set_context({\"user_id\": \"user3\", \"location\":\"Ballantyne, Charlotte, NC\"}):\n",
    "    print(langchain_agent.invoke({\"input\":\"I want to eat with Chef Eric Ripert\"})[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example the user is asking for food like Chef Eric Ripert's but less expensive.\n",
    "The LLM uses the knowledge it has about Chef Eric Riperts restaurant to suggest a less expensive alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jane, since you've recently visited places like Wan Fu and Ru San's, I recommend trying **Hakkasan**. It's an upscale Chinese restaurant that focuses on authentic flavors and high-quality ingredients. You can enjoy dishes like their Peking Duck, Dim Sum Platter, and the Stir-Fried Black Pepper Beef. It's a great choice for a refined dining experience!\n"
     ]
    }
   ],
   "source": [
    "with client.set_context({\"user_id\": \"user3\", \"location\":\"New York\"}):\n",
    "    print(langchain_agent.invoke({\"input\":\"I have never been here, what restaurant is most like the ones I visit\"})[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tecton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
