{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e51112",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42db390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tecton_gen_ai.fco import source_as_knowledge, prompt, AgentService, AgentClient\n",
    "from tecton_gen_ai.testing import make_local_source, set_dev_mode\n",
    "from tecton_gen_ai.testing.utils import make_local_vector_db_config\n",
    "\n",
    "set_dev_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6fad3a",
   "metadata": {},
   "source": [
    "# Setup Sample Feature Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9405e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tecton_gen_ai.testing import make_local_batch_feature_view\n",
    "\n",
    "# user specific money transfer statistics\n",
    "transfer_stats = make_local_batch_feature_view(\n",
    "    \"transfer_stats\",\n",
    "    [\n",
    "        {\"user_id\": 1, \"transfers_in_last_7_days\": 20, \"transfers_in_last_1_year\": 22},\n",
    "        {\"user_id\": 2, \"transfers_in_last_7_days\": 0, \"transfers_in_last_1_year\": 10},\n",
    "    ],\n",
    "    [\"user_id\"],\n",
    "    description = \"User's money transfer stats, abnormal activities could cause account suspension\"  # description for LLM\n",
    ")\n",
    "\n",
    "# user profile info\n",
    "user_profile = make_local_batch_feature_view(\n",
    "    \"user_profile\",\n",
    "    [\n",
    "        {\"user_id\": 1, \"name\": \"Jim\", \"age\": 30, \"account_status\":\"suspended\"},\n",
    "        {\"user_id\": 2, \"name\": \"Mary\", \"age\": 16, \"account_status\":\"active\"},\n",
    "    ],\n",
    "    [\"user_id\"],\n",
    "    description = \"User's name, age and account status\"  # description for LLM\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e4d6b0",
   "metadata": {},
   "source": [
    "## The FAQ Data\n",
    "\n",
    "As expected the FAQ data is text with common user questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d9ef853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Am I eligible to receive a transfer?</td>\n",
       "      <td>You’re eligible to receive a transfer from Tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I get my TectonTransfer account back?</td>\n",
       "      <td>If you think your profile may have been suspen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can I get my account back?</td>\n",
       "      <td>In most cases, it’s easy to get back into your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I receive money using mobile wallets or ho...</td>\n",
       "      <td>You can use home delivery or mobile wallet app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can I send a request via fax?</td>\n",
       "      <td>We are not able to accept subpoenas or other l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Why is my transfer being reviewed by Bancolombia?</td>\n",
       "      <td>There are a couple of reasons Bancolombia migh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Why was my sending limit increase declined?</td>\n",
       "      <td>In some cases, we may not be able to approve t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Will I need to change my sending country befor...</td>\n",
       "      <td>No, your sending country is the country where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Will my info be deleted?</td>\n",
       "      <td>Closing your profile doesn’t delete your infor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Will my recipient be charged for cash pickup?</td>\n",
       "      <td>Your recipient will not be charged any fees fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0                 Am I eligible to receive a transfer?   \n",
       "1            Can I get my TectonTransfer account back?   \n",
       "2                           Can I get my account back?   \n",
       "3    Can I receive money using mobile wallets or ho...   \n",
       "4                        Can I send a request via fax?   \n",
       "..                                                 ...   \n",
       "241  Why is my transfer being reviewed by Bancolombia?   \n",
       "242        Why was my sending limit increase declined?   \n",
       "243  Will I need to change my sending country befor...   \n",
       "244                           Will my info be deleted?   \n",
       "245      Will my recipient be charged for cash pickup?   \n",
       "\n",
       "                                                answer  \n",
       "0    You’re eligible to receive a transfer from Tec...  \n",
       "1    If you think your profile may have been suspen...  \n",
       "2    In most cases, it’s easy to get back into your...  \n",
       "3    You can use home delivery or mobile wallet app...  \n",
       "4    We are not able to accept subpoenas or other l...  \n",
       "..                                                 ...  \n",
       "241  There are a couple of reasons Bancolombia migh...  \n",
       "242  In some cases, we may not be able to approve t...  \n",
       "243  No, your sending country is the country where ...  \n",
       "244  Closing your profile doesn’t delete your infor...  \n",
       "245  Your recipient will not be charged any fees fo...  \n",
       "\n",
       "[246 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "faq_df = pd.read_parquet(\"faq.parquet\")\n",
    "display (faq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad942c7",
   "metadata": {},
   "source": [
    "## Prepare FAQ knowledge for RAG\n",
    "\n",
    "The FAQ text is loaded into a vector search database to provide answers to user's questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6650684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The source description tells the LLM what kind of information it can retrieve from this knowledge base\n",
    "faq_parquet_data = make_local_source(\n",
    "    \"faq\",\n",
    "    faq_df,\n",
    "    description = \"FAQ for TransferApp users\",  # <<<<<<<<\n",
    "    max_rows = len(faq_df)\n",
    ")\n",
    "\n",
    "# calculate embeddings based on the \"question\" such that LLM can find info it needs based on similar questions\n",
    "faq_knowledge = source_as_knowledge(\n",
    "    faq_parquet_data,  # << parquet file of questions and answers\n",
    "    vector_db_config=make_local_vector_db_config(),\n",
    "    vectorize_column=\"question\" # <<<<<<<<\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c820f",
   "metadata": {},
   "source": [
    "## Connect to LLM Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20ac0226-5e03-4231-9e33-10b5250a1d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tecton_gen_ai.testing.interactive import auto_complete, qna\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "openai = ChatOpenAI(model = \"gpt-4o\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7063edc",
   "metadata": {},
   "source": [
    "# Demo Scenario\n",
    "\n",
    "TransferApp is a money transfer company that provides services through a mobile app.  \n",
    "\n",
    "- They have an FAQ that user's can search to find responses to their questions.\n",
    "- They want to create a chatbot that can use FAQ to respond to user questions directly.\n",
    "- They've decided to build a RAG GenAI solution for this purpose.\n",
    "\n",
    "\n",
    "In this demo of Tecton we will show to build a chatbot using the Tecton GenAI Package.\n",
    "\n",
    "- Tecton GenAI SDK to build two version of the chatbot:\n",
    "- We will use Tecton's declarative framework to create:\n",
    "    - prompts \n",
    "    - knowledge base as a tool from the FAQ data\n",
    "    - user features as a tool for personalization\n",
    "    - Agent Service to serve the chatbot functionality in TransferApp\n",
    "\n",
    "\n",
    "# RAG Solution Options\n",
    "\n",
    "<img src=\"images/naive_rag.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19038c40",
   "metadata": {},
   "source": [
    "## With Tecton\n",
    "\n",
    "<img src=\"images/rag_diagram2.png\" width=\"1000\"/>\n",
    "\n",
    "## Managed RAG Chatbot with Tecton\n",
    "- The prompt provides instructions to the LLM\n",
    "- Prepare the FAQ Knowledge base\n",
    "- The AgentService serves the GenAI application through a REST endpoint:\n",
    "    - the prompt\n",
    "    - the FAQ knowledge \n",
    "    - manages the LLM interaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7556b73-dca8-45da-b264-f2a7fcca477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the prompt instructs the LLM to use the FAQ knowledge to answer questions \n",
    "@prompt()\n",
    "def sys_prompt() -> str:\n",
    "    return \"\"\"You are an assistant,\n",
    "    TransferApp is a money transfer service on a mobile application.\n",
    "    You answer questions based on FAQ for TranferApp.\n",
    "    Say you don't know if the questions are not relevant to any questions on FAQ\n",
    "\"\"\"\n",
    "\n",
    "# calculate embeddings based on the \"question\" such that LLM can find info it needs based on similar questions\n",
    "faq_knowledge = source_as_knowledge(\n",
    "    faq_parquet_data,  # << parquet file of questions and answers\n",
    "    vector_db_config=make_local_vector_db_config(),\n",
    "    vectorize_column=\"question\" # <<<<<<<<\n",
    ")\n",
    "\n",
    "rag_service = AgentService(\n",
    "    \"chatbot_context\",\n",
    "    prompts=[sys_prompt],\n",
    "    knowledge=[faq_knowledge]\n",
    ")\n",
    "\n",
    "rag_client = AgentClient.from_local(rag_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4d993e",
   "metadata": {},
   "source": [
    "## A Simple RAG chatbot\n",
    "\n",
    "It uses generally applicable knowledge so all users get the same experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c0350a6-0560-4afd-9945-8aa4862aa112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f651ea19028a4c12b74081b20d15d544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', continuous_update=False, placeholder='Type something'), Output(), Accordion(chil…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qna(rag_client, openai, \"sys_prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c403e3d9",
   "metadata": {},
   "source": [
    " # Adding Customized Context to the Chatbot\n",
    "\n",
    "A more useful chatbot can be created by adding better context and tools for the LLM.\n",
    "\n",
    "<img src=images/personalized_diagram.png width=1000/>\n",
    "\n",
    "\n",
    "## Building a smarter TransferApp chatbot\n",
    "\n",
    "In this example we use two feature pipelines:\n",
    " - **transfer_stats** transfer activity aggregations `transfers_last_7days` & `transfers_last_1year`\n",
    " - **user_profile**  data containing `name`, `age` & `account_status`\n",
    "\n",
    "We build a contextualized prompt to provide a personalized experience.\n",
    "\n",
    "We build an LLM Agent that delivers: \n",
    "- FAQ based knowledge\n",
    "- contextualized prompt \n",
    "- tools to access user specific data : **transfer_stats** & **user_profile** data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a71e1b30-9d08-495b-8171-a15999f4aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tecton_gen_ai.fco import tool\n",
    "\n",
    "\n",
    "# this prompt incorporates user_profile context in the prompt  \n",
    "@prompt(sources=[user_profile])\n",
    "def sys_prompt_fv(user_profile) -> str:\n",
    "    return f\"\"\"\n",
    "            You are an assistant, \n",
    "            You answer questions based on the FAQ for TransferApp.\n",
    "            Say you don't know if the questions are not relevant to any questions on FAQ.\n",
    "            You are serving {user_profile['name']}, whose age is {user_profile['age']}.\n",
    "            Address the user by name.\n",
    "            Consult the user's money transfer stats if needed to respond to their question.\n",
    "    \"\"\"\n",
    "    \n",
    "# a service with user context for personalization\n",
    "service_with_fv = AgentService(\n",
    "    \"chatbot_with_personalization\",\n",
    "    prompts=[sys_prompt_fv],\n",
    "    knowledge=[faq_knowledge],\n",
    "    tools=[transfer_stats, user_profile],  # <<<<<< the LLM can now query this user info as needed\n",
    ")\n",
    "\n",
    "client_with_fv = AgentClient.from_local(service_with_fv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809702c6",
   "metadata": {},
   "source": [
    "## A chatbot with user context\n",
    "\n",
    "The chatbot identifies the user with a `user_id` based on their session.\n",
    "\n",
    "Tecton makes use of the `user_id` to personalize the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aa4a61c-b16d-48ae-beb5-7be831292797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d46000401a4afe8350040ee0c6c232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', continuous_update=False, placeholder='Type something'), Output(), Accordion(chil…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the chatbot has the user identified based on their session\n",
    "qna(client_with_fv, openai, \"sys_prompt_fv\", context={\"user_id\":2}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b346296f",
   "metadata": {},
   "source": [
    "# Tecton Apply\n",
    "\n",
    "`tecton apply` command will deploy:\n",
    "- feature views, \n",
    "- prompts, \n",
    "- knowledge bases \n",
    "- agents\n",
    "\n",
    "What happens when you `tecton apply`:\n",
    "\n",
    "- Data Pipelines are automatically created, scheduled, orchestrated and monitored \n",
    "- Data is kept up to date, for streaming and batch sources\n",
    "- Tecton's Retrieval system provide low-latency serving of the features and agent services\n",
    "- Tecton deploys API endpoint for the AgentService that \n",
    "    - controls authenticated access to the chatbot / genai app\n",
    "    - auto-scales\n",
    "    - real-time inputs and their processing logic is also deployed\n",
    "\n",
    "Output from `tecton apply`:\n",
    "```\n",
    "insert output here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876eb7c3",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Tecton's Declarative Framework makes it easy to build Generative AI applications\n",
    "- prompts, knowledge bases and personalized tools are just a few lines of code\n",
    "- iterating to do prompt engingeering is fast\n",
    "- knowledge base management is automatic\n",
    "- incorporating personalization through enriched prompts and features as tools is simple\n",
    "\n",
    "The Tecton Platform gets the GenAI app into production fast by automating:\n",
    "- data engineering \n",
    "- versioning\n",
    "- data lineage\n",
    "- governance\n",
    "- orchestration\n",
    "- scheduling\n",
    "- monitoring\n",
    "\n",
    "You focus on the Generative AI behavior you want to produce. Tecton takes care of the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd59e32d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
