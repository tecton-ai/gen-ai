{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e51112",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42db390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tecton_gen_ai.fco import source_as_knowledge, prompt, AgentService, AgentClient\n",
    "from tecton_gen_ai.testing import make_local_source, set_dev_mode\n",
    "from tecton_gen_ai.testing.utils import make_local_vector_db_config\n",
    "\n",
    "set_dev_mode()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6fad3a",
   "metadata": {},
   "source": [
    "# Setup Sample Feature Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9405e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tecton_gen_ai.testing import make_local_batch_feature_view\n",
    "\n",
    "# user specific money transfer statistics\n",
    "transfer_stats = make_local_batch_feature_view(\n",
    "    \"transfer_stats\",\n",
    "    [\n",
    "        {\"user_id\": 1, \"transfers_in_last_7_days\": 20, \"transfers_in_last_1_year\": 22},\n",
    "        {\"user_id\": 2, \"transfers_in_last_7_days\": 0, \"transfers_in_last_1_year\": 10},\n",
    "    ],\n",
    "    [\"user_id\"],\n",
    "    description = \"User's money transfer stats, abnormal activities could cause account suspension\"  # description for LLM\n",
    ")\n",
    "\n",
    "# user profile info\n",
    "user_profile = make_local_batch_feature_view(\n",
    "    \"user_profile\",\n",
    "    [\n",
    "        {\"user_id\": 1, \"name\": \"Jim\", \"age\": 30, \"account_status\":\"suspended\"},\n",
    "        {\"user_id\": 2, \"name\": \"Mary\", \"age\": 16, \"account_status\":\"active\"},\n",
    "    ],\n",
    "    [\"user_id\"],\n",
    "    description = \"User's name, age and account status\"  # description for LLM\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e4d6b0",
   "metadata": {},
   "source": [
    "# Chatbot for Money Transfer App\n",
    "\n",
    "This money transfer service app uses a chatbot that responds to user questions based on their public FAQ.\n",
    "\n",
    "The chatbot uses a RAG solution.\n",
    "\n",
    "<Insert image with high level RAG architecture.>\n",
    "\n",
    "## The FAQ Data\n",
    "\n",
    "As expected the FAQ data is text with common user questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9ef853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Am I eligible to receive a transfer?</td>\n",
       "      <td>You’re eligible to receive a transfer from Rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I get my Remitly account back?</td>\n",
       "      <td>If you think your profile may have been suspen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can I get my account back?</td>\n",
       "      <td>In most cases, it’s easy to get back into your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I receive money using mobile wallets or ho...</td>\n",
       "      <td>You can use home delivery or mobile wallet app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can I send a request via fax?</td>\n",
       "      <td>We are not able to accept subpoenas or other l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Why is my transfer being reviewed by Bancolombia?</td>\n",
       "      <td>There are a couple of reasons Bancolombia migh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Why was my sending limit increase declined?</td>\n",
       "      <td>In some cases, we may not be able to approve t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Will I need to change my sending country befor...</td>\n",
       "      <td>No, your sending country is the country where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Will my info be deleted?</td>\n",
       "      <td>Closing your profile doesn’t delete your infor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Will my recipient be charged for cash pickup?</td>\n",
       "      <td>Your recipient will not be charged any fees fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0                 Am I eligible to receive a transfer?   \n",
       "1                   Can I get my Remitly account back?   \n",
       "2                           Can I get my account back?   \n",
       "3    Can I receive money using mobile wallets or ho...   \n",
       "4                        Can I send a request via fax?   \n",
       "..                                                 ...   \n",
       "241  Why is my transfer being reviewed by Bancolombia?   \n",
       "242        Why was my sending limit increase declined?   \n",
       "243  Will I need to change my sending country befor...   \n",
       "244                           Will my info be deleted?   \n",
       "245      Will my recipient be charged for cash pickup?   \n",
       "\n",
       "                                                answer  \n",
       "0    You’re eligible to receive a transfer from Rem...  \n",
       "1    If you think your profile may have been suspen...  \n",
       "2    In most cases, it’s easy to get back into your...  \n",
       "3    You can use home delivery or mobile wallet app...  \n",
       "4    We are not able to accept subpoenas or other l...  \n",
       "..                                                 ...  \n",
       "241  There are a couple of reasons Bancolombia migh...  \n",
       "242  In some cases, we may not be able to approve t...  \n",
       "243  No, your sending country is the country where ...  \n",
       "244  Closing your profile doesn’t delete your infor...  \n",
       "245  Your recipient will not be charged any fees fo...  \n",
       "\n",
       "[246 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "faq_df = pd.read_parquet(\"faq.parquet\")\n",
    "display (faq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad942c7",
   "metadata": {},
   "source": [
    "## Adding FAQ knowledge for RAG\n",
    "\n",
    "The FAQ text is loaded into a vector search database to provide answers to user's questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2558cf98-4d5e-4cc3-a118-ab6b104ea58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The source description tells the LLM what kind of information it can retrieve from this knowledge base\n",
    "src = make_local_source(\n",
    "    \"faq\",\n",
    "    faq_df,\n",
    "    description = \"FAQ for TectonTransfer users\",  # <<<<<<<<\n",
    "    max_rows = len(faq_df)\n",
    ")\n",
    "\n",
    "# calculate embeddings based on the \"question\" such that LLM can find info it needs based on similar questions\n",
    "faq_knowledge = source_as_knowledge(\n",
    "    src,\n",
    "    vector_db_config=make_local_vector_db_config(),\n",
    "    vectorize_column=\"question\" # <<<<<<<<\n",
    ")\n",
    "\n",
    "# the prompt instructs the LLM to use the FAQ knowledge to answer questions \n",
    "@prompt()\n",
    "def sys_prompt() -> str:\n",
    "    return \"\"\"You are an assistant,\n",
    "    TectonTransfer is a money transfer service on a mobile application.\n",
    "you answer questions based on FAQ for TectonTranfer.\n",
    "Say you don't know if the questions are not relevant to any questions on FAQ\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19038c40",
   "metadata": {},
   "source": [
    "## The AgentService \n",
    "\n",
    "AgentService provides context to the LLM by providing the system prompt and sets of knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7556b73-dca8-45da-b264-f2a7fcca477c",
   "metadata": {},
   "outputs": [
    {
     "ename": "UserCodeError",
     "evalue": "error caused by user configuration has occurred:\nPandas pipeline function (feature view 'faq_batch') failed with exception\n1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/tecton/lib/python3.9/site-packages/tecton_core/query/pandas/nodes.py:239\u001b[0m, in \u001b[0;36mPandasFeatureViewPipelineNode._call_pandas_udf_and_verify_result\u001b[0;34m(self, transformation_node, user_function, expected_schema)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43muser_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tecton/lib/python3.9/site-packages/tecton_gen_ai/knowledge.py:204\u001b[0m, in \u001b[0;36msource_as_knowledge.<locals>.ingest_0\u001b[0;34m(bs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mingest_0\u001b[39m(bs):\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mingest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tecton/lib/python3.9/site-packages/tecton_gen_ai/knowledge.py:189\u001b[0m, in \u001b[0;36msource_as_knowledge.<locals>.ingest\u001b[0;34m(bs, *args)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bs\u001b[38;5;241m.\u001b[39massign(dummy\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m vs: VectorStore \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_json_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m texts \u001b[38;5;241m=\u001b[39m bs[vectorize_column]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tecton/lib/python3.9/site-packages/tecton_gen_ai/utils/config_wrapper.py:34\u001b[0m, in \u001b[0;36mfrom_json_config\u001b[0;34m(json_str, external_kwargs, use_cache)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_json_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexternal_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ConfigWrapper\u001b[38;5;241m.\u001b[39mfrom_json(json_str)\u001b[38;5;241m.\u001b[39minstantiate(external_kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tecton/lib/python3.9/site-packages/tecton_gen_ai/utils/config_wrapper.py:40\u001b[0m, in \u001b[0;36m_from_json_config\u001b[0;34m(json_str, kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_json_config\u001b[39m(json_str: \u001b[38;5;28mstr\u001b[39m, kwargs: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mConfigWrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tecton/lib/python3.9/site-packages/tecton_gen_ai/utils/config_wrapper.py:58\u001b[0m, in \u001b[0;36mConfigWrapper.instantiate\u001b[0;34m(self, external_kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m tf \u001b[38;5;241m=\u001b[39m _InitTraverser(external_kwargs)\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_type(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mtf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tecton/lib/python3.9/site-packages/tecton_gen_ai/utils/config_wrapper.py:89\u001b[0m, in \u001b[0;36m_InitTraverser.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_external_kwargs[obj\u001b[38;5;241m.\u001b[39mname]\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tecton/lib/python3.9/site-packages/tecton_gen_ai/utils/config_wrapper.py:79\u001b[0m, in \u001b[0;36m_Traverser.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mself\u001b[39m(k): \u001b[38;5;28mself\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tecton/lib/python3.9/site-packages/tecton_gen_ai/utils/config_wrapper.py:79\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mself\u001b[39m(k): \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tecton/lib/python3.9/site-packages/tecton_gen_ai/utils/config_wrapper.py:86\u001b[0m, in \u001b[0;36m_InitTraverser.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, ConfigWrapper):\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_external_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, ExternalArgument):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tecton/lib/python3.9/site-packages/tecton_gen_ai/utils/config_wrapper.py:58\u001b[0m, in \u001b[0;36mConfigWrapper.instantiate\u001b[0;34m(self, external_kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m tf \u001b[38;5;241m=\u001b[39m _InitTraverser(external_kwargs)\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tecton/lib/python3.9/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mUserCodeError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m rag_service \u001b[38;5;241m=\u001b[39m AgentService(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchatbot_context\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     prompts\u001b[38;5;241m=\u001b[39m[sys_prompt],\n\u001b[1;32m      4\u001b[0m     knowledge\u001b[38;5;241m=\u001b[39m[faq_knowledge]\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m rag_client \u001b[38;5;241m=\u001b[39m \u001b[43mAgentClient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrag_service\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tecton/lib/python3.9/site-packages/tecton_gen_ai/agent/client.py:119\u001b[0m, in \u001b[0;36mAgentClient.from_local\u001b[0;34m(service)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_local\u001b[39m(service: AgentService) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgentClient\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    Create a client for a local agent service. This is for testing\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    and development purposes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m        AgentClient: The agent client\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_AgentClientLocal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tecton/lib/python3.9/site-packages/tecton_gen_ai/agent/client.py:549\u001b[0m, in \u001b[0;36m_AgentClientLocal.__init__\u001b[0;34m(self, service)\u001b[0m\n\u001b[1;32m    547\u001b[0m start \u001b[38;5;241m=\u001b[39m attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    548\u001b[0m end \u001b[38;5;241m=\u001b[39m attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_time\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 549\u001b[0m \u001b[43mbfv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_transformation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIngested knowledge \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to vector db\u001b[39m\u001b[38;5;124m\"\u001b[39m, bfv\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tecton/lib/python3.9/site-packages/tecton/_internals/sdk_decorators.py:211\u001b[0m, in \u001b[0;36msdk_public_method.<locals>.inner_decorator.<locals>._sdk_public_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     thread_local_data\u001b[38;5;241m.\u001b[39min_tecton_sdk_public_method_wrapper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_invoke_and_transform_errors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manalytics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43malready_in_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypecheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     thread_local_data\u001b[38;5;241m.\u001b[39min_tecton_sdk_public_method_wrapper \u001b[38;5;241m=\u001b[39m already_in_wrapper\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tecton/lib/python3.9/site-packages/tecton/_internals/sdk_decorators.py:280\u001b[0m, in \u001b[0;36m_invoke_and_transform_errors\u001b[0;34m(func, args, kwargs, arg_names, log_analytics, is_top_level, typecheck)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# for user-caused errors we want to minimize the traceback for cleaner output.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# nested exception (ie, exception from UDF) though still might have some meaningful traceback.\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conf\u001b[38;5;241m.\u001b[39mget_bool(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTECTON_DEBUG\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39mcan_drop_traceback:\n\u001b[0;32m--> 280\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mUserCodeError\u001b[0m: error caused by user configuration has occurred:\nPandas pipeline function (feature view 'faq_batch') failed with exception\n1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "rag_service = AgentService(\n",
    "    \"chatbot_context\",\n",
    "    prompts=[sys_prompt],\n",
    "    knowledge=[faq_knowledge]\n",
    ")\n",
    "\n",
    "rag_client = AgentClient.from_local(rag_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c820f",
   "metadata": {},
   "source": [
    "## Add an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20ac0226-5e03-4231-9e33-10b5250a1d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tecton_gen_ai.testing.interactive import auto_complete, qna\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "openai = ChatOpenAI(model = \"gpt-4o\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4d993e",
   "metadata": {},
   "source": [
    "## A RAG-based chatbot\n",
    "\n",
    "No personalization, all users get the same experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c0350a6-0560-4afd-9945-8aa4862aa112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548c6470517d4d7f8110b02023707d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', continuous_update=False, placeholder='Type something'), Output(), Accordion(chil…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qna(rag_client, openai, \"sys_prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c403e3d9",
   "metadata": {},
   "source": [
    "# Personalized Chatbot\n",
    "\n",
    "A more useful chatbot can be created by adding better context and tools for the LLM.\n",
    "\n",
    "insert image with data pipelines for \n",
    " - transaction stats aggregation  with `transfers_last_7days` & `transfers_last_1year`\n",
    " - user profile with `name`, `age` & `account_status`\n",
    " - With Tecton -> the data is always up to date, \n",
    " - Agent delivers \n",
    "    - FAQ based knowledge\n",
    "    - contextualized prompt, \n",
    "    - user and transaction data tools to answer based on user's situation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a71e1b30-9d08-495b-8171-a15999f4aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tecton_gen_ai.fco import tool\n",
    "\n",
    "\n",
    "# this prompt incorporates user_profile context in the prompt  \n",
    "@prompt(sources=[user_profile])\n",
    "def sys_prompt_fv(user_profile) -> str:\n",
    "    return f\"\"\"\n",
    "You are an assistant, \n",
    "You answer questions based on FAQ list.\n",
    "Say you don't know if the questions are not relevant to any questions on FAQ.\n",
    "You are serving {user_profile['name']}, whose age is {user_profile['age']}.\n",
    "Address the user by name.\n",
    "Consult the user's money transfer stats if needed to respond to their question.\n",
    "\"\"\"\n",
    "    \n",
    "# a service with user context for personalization\n",
    "service_with_fv = AgentService(\n",
    "    \"chatbot_with_personalization\",\n",
    "    prompts=[sys_prompt_fv],\n",
    "    knowledge=[faq_knowledge],\n",
    "    tools=[transfer_stats, user_profile],  # <<<<<< the LLM can now query this user info as needed\n",
    ")\n",
    "\n",
    "client_with_fv = AgentClient.from_local(service_with_fv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809702c6",
   "metadata": {},
   "source": [
    "## A chatbot with user context\n",
    "\n",
    "The chatbot identifies the user with a `user_id` based on their session.\n",
    "\n",
    "Tecton makes use of the `user_id` to personalize the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4aa4a61c-b16d-48ae-beb5-7be831292797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1a1df113e54c2bbd8515854d6e3761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', continuous_update=False, placeholder='Type something'), Output(), Accordion(chil…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the chatbot has the user identified based on their session\n",
    "qna(client_with_fv, openai, \"sys_prompt_fv\", context={\"user_id\":2}) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
