{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextualized Prompts \n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/tecton-ai/gen-ai/blob/main/context-aware-prompt.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" width=\"150\"/>\n",
    "</a>\n",
    "\n",
    "This tutorial guides you through creating an LLM generated restaurant recommendation function.\n",
    "This is an example of how Tecton managed and contextualized prompts enable personalization.\n",
    "\n",
    "It uses Tecton's real-time enriched prompts to provide current context to the LLM in order to improve the quality of its response. \n",
    "This tutorial demonstrates both LangChain and LlamaIndex integration with Tecton prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'tecton-gen-ai[tecton,langchain,llama-index,dev]' langchain-openai llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log in to Tecton\n",
    "Make sure to hit enter after pasting in your authentication token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tecton\n",
    "\n",
    "tecton.login(\"explore.tecton.ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tecton Prompt\n",
    "\n",
    "In the following cell you'll create a Tecton Agent with a system prompt that provides instructions to the LLM. The instructions are parameterized with a specific user's data. \n",
    "\n",
    "The agent creation function takes a Tecton feature view as input which is used at run-time to acquire the latest values of the parameters for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tecton_gen_ai.agent import AgentClient, AgentService\n",
    "from tecton_gen_ai.fco import prompt\n",
    "from tecton_gen_ai.utils.tecton import make_request_source\n",
    "\n",
    "\n",
    "def restaurant_recommender_agent( user_info):    \n",
    "    \n",
    "    location_request = make_request_source(location = str)\n",
    "\n",
    "    @prompt(sources=[ location_request, user_info])\n",
    "    def sys_prompt(location_request, user_info ):\n",
    "        name = user_info[\"name\"]\n",
    "        food_preference = user_info[\"food_preference\"]\n",
    "        location = location_request[\"location\"]\n",
    "        return f\"\"\"\n",
    "        You are a consierge service that recommends restaurants.\n",
    "        You are serving {name}. Address them by name. \n",
    "        Respond to the user query about dining. \n",
    "        If the user asks for a restaurant recommendation respond with a specific restaurant that you know and suggested menu items. \n",
    "        Suggest restaurants that are in {location}. \n",
    "        If the user does not provide a cuisine or food preference, choose a {food_preference} restaurant.\n",
    "        \"\"\"\n",
    "        \n",
    "    return AgentService(\n",
    "        name=\"restaurant_recommender\",\n",
    "        prompts=[ sys_prompt],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above uses a single feature view as input. Tecton Agents can make use of any number of feature views deployed on the Tecton platform to provide up to date context from any features deployed on the platform. \n",
    "\n",
    "Notice that the `sys_prompt` function additionally takes the `location` parameter in the prompt. This instructs Tecton to acquire the location information at request time. Location is a good example of a real-time input given that it would presumably come from a device's GPS function. A combination of existing feature pipelines and real-time parameters can be used for any prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data\n",
    "\n",
    "In order to keep this notebook self-contained, you will create a mock feature view with some hard-coded data.\n",
    "In a real application, you would use Feature Views that continuously update feature values and therefore provide up-to-date context to the LLM application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tecton import RequestSource\n",
    "from tecton.types import Field, String\n",
    "\n",
    "\n",
    "from tecton_gen_ai.testing import make_local_batch_feature_view\n",
    "\n",
    "\n",
    "mock_data = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"user_id\": \"user1\",\n",
    "                \"name\": \"Jim\",\n",
    "                \"age\": 30,\n",
    "                \"food_preference\": \"American\",\n",
    "            },\n",
    "            {\n",
    "                \"user_id\": \"user2\",\n",
    "                \"name\": \"John\",\n",
    "                \"age\": 40,\n",
    "                \"food_preference\": \"Italian\",\n",
    "            },\n",
    "            {\n",
    "                \"user_id\": \"user3\",\n",
    "                \"name\": \"Jane\",\n",
    "                \"age\": 50,\n",
    "                \"food_preference\": \"Chinese\",\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "user_preference_fv = make_local_batch_feature_view(\n",
    "        \"user_info\", mock_data, entity_keys=[\"user_id\"], description=\"User's profile with name, age and food preference.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature view identifies the key `user_id` that is needed to access a user's data, this attribute must be provided when using the feature view in a prompt. \n",
    "\n",
    "In the following cell, you will test the prompt through an AgentClient's invoke_prompt method using a `user_id` and a `location` value. The `user_id` is used to retrieve a specific user's values. The location parameter is a request time parameter so you'll need to provide that value too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    You are a consierge service that recommends restaurants.</span><span style=\"background-color: #272822\">                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    You are serving Jane. Address them by name. </span><span style=\"background-color: #272822\">                                                                  </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    Respond to the user query about dining. </span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    If the user asks for a restaurant recommendation respond with a specific restaurant that you know and suggest</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">menu items. </span><span style=\"background-color: #272822\">                                                                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    Suggest restaurants that are in Chicago. </span><span style=\"background-color: #272822\">                                                                     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    If the user does not provide a cuisine or food preference, choose a Chinese restaurant.</span><span style=\"background-color: #272822\">                       </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    You are a consierge service that recommends restaurants.\u001b[0m\u001b[48;2;39;40;34m                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    You are serving Jane. Address them by name. \u001b[0m\u001b[48;2;39;40;34m                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    Respond to the user query about dining. \u001b[0m\u001b[48;2;39;40;34m                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    If the user asks for a restaurant recommendation respond with a specific restaurant that you know and suggest\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmenu items. \u001b[0m\u001b[48;2;39;40;34m                                                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    Suggest restaurants that are in Chicago. \u001b[0m\u001b[48;2;39;40;34m                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    If the user does not provide a cuisine or food preference, choose a Chinese restaurant.\u001b[0m\u001b[48;2;39;40;34m                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tecton_gen_ai.testing.utils import print_md\n",
    "\n",
    "# create the Tecton Agent\n",
    "recommender_agent = restaurant_recommender_agent(user_preference_fv )\n",
    "\n",
    "# create a client to invoke with the agent\n",
    "client = AgentClient.from_local( recommender_agent )\n",
    "\n",
    "#test the agent using \"sys_prompt\" prompt\n",
    "print_md(client.invoke_prompt(\"sys_prompt\", kwargs=dict(user_id=\"user3\", location=\"Chicago\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporate Contextualized Prompt into a LangChain agent\n",
    "\n",
    "The Tecton AgentClient can be used to create a LangChain agent which will use the enriched prompt to generate a response.\n",
    "In the cell below you will instantiate an LLM model using OpenAI.\n",
    "\n",
    "Obtain an [OpenAI API key](https://platform.openai.com/api-keys) and replace \"your-openai-key\" in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai as oa\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# replace with your key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key\"\n",
    "\n",
    "# instantiate LLM model\n",
    "gpt_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "#create a lang chain agent that uses the system_prompt \n",
    "lc_agent = client.make_agent(llm=gpt_llm, system_prompt = \"sys_prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it out\n",
    "\n",
    "In the following cells you can see how the response changes based on the `user_id` and the `location` provided resulting in a personalized response for each user and based on their current location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Hi Jim! I recommend trying The Capital Grille in Charlotte, NC. This upscale steakhouse offers a refined dining    \n",
       "experience with a fantastic selection of dry-aged steaks and fresh seafood. Their extensive wine list complements  \n",
       "the menu beautifully.                                                                                              \n",
       "\n",
       "I suggest the Bone-In Ribeye or the Filet Mignon, paired with their famous Lobster Mac 'n' Cheese as a side. The   \n",
       "ambiance is perfect for a nice evening out, and the service is top-notch. It's a great choice if you're looking to \n",
       "enjoy a special meal tonight!                                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Hi Jim! I recommend trying The Capital Grille in Charlotte, NC. This upscale steakhouse offers a refined dining    \n",
       "experience with a fantastic selection of dry-aged steaks and fresh seafood. Their extensive wine list complements  \n",
       "the menu beautifully.                                                                                              \n",
       "\n",
       "I suggest the Bone-In Ribeye or the Filet Mignon, paired with their famous Lobster Mac 'n' Cheese as a side. The   \n",
       "ambiance is perfect for a nice evening out, and the service is top-notch. It's a great choice if you're looking to \n",
       "enjoy a special meal tonight!                                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with client.set_context({\"user_id\":\"user1\", \"location\":\"Charlotte, NC\"}):\n",
    "    print_md(lc_agent.invoke({\"input\":\"suggest a restaurant for tonight and tell me why you suggest it\"})[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Hi Jim! I recommend trying <span style=\"font-weight: bold\">The Smith</span> in New York, NY. This American brasserie has a lively atmosphere and is known \n",
       "for its delicious comfort food.                                                                                    \n",
       "\n",
       "I suggest starting with their famous Mac &amp; Cheese or the Crispy Brussels Sprouts. For the main course, you can't go\n",
       "wrong with their Classic Burger or the Roasted Chicken. They also have a great selection of cocktails to complement\n",
       "your meal.                                                                                                         \n",
       "\n",
       "The combination of great food, a vibrant setting, and attentive service makes The Smith a fantastic choice for a   \n",
       "fun night out. Enjoy your dinner!                                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Hi Jim! I recommend trying \u001b[1mThe Smith\u001b[0m in New York, NY. This American brasserie has a lively atmosphere and is known \n",
       "for its delicious comfort food.                                                                                    \n",
       "\n",
       "I suggest starting with their famous Mac & Cheese or the Crispy Brussels Sprouts. For the main course, you can't go\n",
       "wrong with their Classic Burger or the Roasted Chicken. They also have a great selection of cocktails to complement\n",
       "your meal.                                                                                                         \n",
       "\n",
       "The combination of great food, a vibrant setting, and attentive service makes The Smith a fantastic choice for a   \n",
       "fun night out. Enjoy your dinner!                                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with client.set_context({\"user_id\":\"user1\", \"location\":\"New York, NY\"}):\n",
    "    print_md(lc_agent.invoke({\"input\":\"suggest a restaurant for tonight and tell me why you suggest it\"})[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Hi John! I recommend trying Carbone, an iconic Italian restaurant in New York, NY. Carbone offers a vibrant        \n",
       "atmosphere and is known for its classic Italian-American dishes.                                                   \n",
       "\n",
       "Some must-try menu items include their famous Spicy Rigatoni Vodka, which is rich and creamy with a kick, and the  \n",
       "Veal Parmesan that’s perfectly breaded and tender. Don't miss out on their Tiramisu for dessert—it's a delightful  \n",
       "way to end your meal!                                                                                              \n",
       "\n",
       "The combination of delicious food and lively ambiance makes Carbone a fantastic choice for a memorable dining      \n",
       "experience tonight. Enjoy!                                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Hi John! I recommend trying Carbone, an iconic Italian restaurant in New York, NY. Carbone offers a vibrant        \n",
       "atmosphere and is known for its classic Italian-American dishes.                                                   \n",
       "\n",
       "Some must-try menu items include their famous Spicy Rigatoni Vodka, which is rich and creamy with a kick, and the  \n",
       "Veal Parmesan that’s perfectly breaded and tender. Don't miss out on their Tiramisu for dessert—it's a delightful  \n",
       "way to end your meal!                                                                                              \n",
       "\n",
       "The combination of delicious food and lively ambiance makes Carbone a fantastic choice for a memorable dining      \n",
       "experience tonight. Enjoy!                                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with client.set_context({\"user_id\":\"user2\", \"location\":\"New York, NY\"}):\n",
    "    print_md(lc_agent.invoke({\"input\":\"suggest a restaurant for tonight and tell me why you suggest it\"})[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Hi Jane! I recommend trying \"Mimi Cheng's Dumpling Bar\" in Charlotte, NC. This cozy spot specializes in delicious  \n",
       "handmade dumplings and offers a variety of options that cater to different tastes.                                 \n",
       "\n",
       "You should definitely try their pork and chive dumplings, which are a crowd favorite, as well as their spicy       \n",
       "Sichuan noodles for a flavorful kick. The ambiance is warm and inviting, making it perfect for a nice evening out. \n",
       "Enjoy your dinner!                                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Hi Jane! I recommend trying \"Mimi Cheng's Dumpling Bar\" in Charlotte, NC. This cozy spot specializes in delicious  \n",
       "handmade dumplings and offers a variety of options that cater to different tastes.                                 \n",
       "\n",
       "You should definitely try their pork and chive dumplings, which are a crowd favorite, as well as their spicy       \n",
       "Sichuan noodles for a flavorful kick. The ambiance is warm and inviting, making it perfect for a nice evening out. \n",
       "Enjoy your dinner!                                                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with client.set_context({\"user_id\":\"user3\", \"location\":\"Charlotte, NC\"}):\n",
    "    print_md(lc_agent.invoke({\"input\":\"suggest a restaurant for tonight and tell me why you suggest it\"})[\"output\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporate Contextualized Prompt into a LlamaIndex agent\n",
    "\n",
    "The Tecton AgentClient can also be used to create a LlamaIndex agent which will use the enriched prompt to generate a response.\n",
    "In the cell below you will instantiate an LLM model but this time using LlamaIndex's integration with OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# instantiate LLM model\n",
    "gpt_llm = OpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it out\n",
    "\n",
    "In the following cells you can see how the response changes based on the `user_id` and the `location` provided resulting in a personalized response for each user and based on their current location.\n",
    "\n",
    "Notice that the LlamaIndex agent `li_agent`uses the `chat` method vs LangChain's `invoke` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Hi Jim! I recommend trying The Capital Grille in Charlotte. It's a fantastic American steakhouse known for its     \n",
       "dry-aged steaks and extensive wine list. The ambiance is elegant, making it perfect for a nice evening out.        \n",
       "\n",
       "I suggest starting with their famous Lobster and Crab Cakes, followed by the Bone-In Ribeye, which is incredibly   \n",
       "flavorful. Don’t forget to pair your meal with a glass of wine from their impressive selection. The service is     \n",
       "top-notch, and the overall dining experience is exceptional. Enjoy your dinner!                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Hi Jim! I recommend trying The Capital Grille in Charlotte. It's a fantastic American steakhouse known for its     \n",
       "dry-aged steaks and extensive wine list. The ambiance is elegant, making it perfect for a nice evening out.        \n",
       "\n",
       "I suggest starting with their famous Lobster and Crab Cakes, followed by the Bone-In Ribeye, which is incredibly   \n",
       "flavorful. Don’t forget to pair your meal with a glass of wine from their impressive selection. The service is     \n",
       "top-notch, and the overall dining experience is exceptional. Enjoy your dinner!                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create a llama-index agent that uses the system_prompt \n",
    "li_agent = client.make_agent(llm=gpt_llm, system_prompt = \"sys_prompt\")\n",
    "\n",
    "# context: user1 in Charlotte\n",
    "with client.set_context({\"user_id\":\"user1\", \"location\":\"Charlotte, NC\"}):\n",
    "    print_md(li_agent.chat(\"suggest a restaurant for tonight and tell me why you suggest it\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Hi Jim! I recommend trying out \"The Smith,\" located in the East Village. It's a vibrant American brasserie known   \n",
       "for its lively atmosphere and delicious comfort food.                                                              \n",
       "\n",
       "You should definitely try their famous mac and cheese, which is a crowd favorite, and the crispy Brussels sprouts  \n",
       "for a tasty side. If you're in the mood for something heartier, their steak frites is a fantastic choice.          \n",
       "\n",
       "The ambiance is perfect for a casual yet enjoyable dining experience, making it a great spot for tonight. Enjoy    \n",
       "your meal!                                                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Hi Jim! I recommend trying out \"The Smith,\" located in the East Village. It's a vibrant American brasserie known   \n",
       "for its lively atmosphere and delicious comfort food.                                                              \n",
       "\n",
       "You should definitely try their famous mac and cheese, which is a crowd favorite, and the crispy Brussels sprouts  \n",
       "for a tasty side. If you're in the mood for something heartier, their steak frites is a fantastic choice.          \n",
       "\n",
       "The ambiance is perfect for a casual yet enjoyable dining experience, making it a great spot for tonight. Enjoy    \n",
       "your meal!                                                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# since llama-index chat is stateful, you should create another instance if there is a change in context\n",
    "li_agent = client.make_agent(llm=gpt_llm, system_prompt = \"sys_prompt\")\n",
    "\n",
    "# context: user1 in New York\n",
    "with client.set_context({\"user_id\":\"user1\", \"location\":\"New York, NY\"}):\n",
    "    print_md(li_agent.chat(\"suggest a restaurant for tonight and tell me why you suggest it\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Hi John! I recommend trying <span style=\"font-weight: bold\">Caffe Siena</span> in Charlotte, NC. This charming Italian restaurant offers a cozy atmosphere\n",
       "and a delightful menu that features authentic Italian dishes.                                                      \n",
       "\n",
       "You might want to start with their <span style=\"font-weight: bold\">Bruschetta</span> as an appetizer, followed by the <span style=\"font-weight: bold\">Fettuccine Alfredo</span> or the <span style=\"font-weight: bold\">Chicken </span>  \n",
       "<span style=\"font-weight: bold\">Piccata</span> for your main course. They also have a lovely selection of wines to complement your meal.                  \n",
       "\n",
       "I suggest Caffe Siena because it combines great food with a warm ambiance, making it perfect for a nice evening    \n",
       "out. Enjoy your dinner!                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Hi John! I recommend trying \u001b[1mCaffe Siena\u001b[0m in Charlotte, NC. This charming Italian restaurant offers a cozy atmosphere\n",
       "and a delightful menu that features authentic Italian dishes.                                                      \n",
       "\n",
       "You might want to start with their \u001b[1mBruschetta\u001b[0m as an appetizer, followed by the \u001b[1mFettuccine Alfredo\u001b[0m or the \u001b[1mChicken \u001b[0m  \n",
       "\u001b[1mPiccata\u001b[0m for your main course. They also have a lovely selection of wines to complement your meal.                  \n",
       "\n",
       "I suggest Caffe Siena because it combines great food with a warm ambiance, making it perfect for a nice evening    \n",
       "out. Enjoy your dinner!                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# since llama-index chat is stateful, you should create another instance if there is a change in context\n",
    "li_agent = client.make_agent(llm=gpt_llm, system_prompt = \"sys_prompt\")\n",
    "\n",
    "# context: user2 in Charlotte\n",
    "with client.set_context({\"user_id\":\"user2\", \"location\":\"Charlotte, NC\"}):\n",
    "    print_md(li_agent.chat(\"suggest a restaurant for tonight and tell me why you suggest it\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Hi Jane! I recommend trying \"Lang Van,\" a fantastic Chinese restaurant in Charlotte, NC. It's known for its        \n",
       "authentic flavors and cozy atmosphere.                                                                             \n",
       "\n",
       "You should definitely try their \"Pho\" for a comforting bowl of noodle soup, and the \"Spring Rolls\" are a perfect   \n",
       "appetizer to start your meal. The \"Kung Pao Chicken\" is also a crowd favorite, packed with flavor and a bit of     \n",
       "spice.                                                                                                             \n",
       "\n",
       "Lang Van is a great choice for a delightful dining experience tonight! Enjoy!                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Hi Jane! I recommend trying \"Lang Van,\" a fantastic Chinese restaurant in Charlotte, NC. It's known for its        \n",
       "authentic flavors and cozy atmosphere.                                                                             \n",
       "\n",
       "You should definitely try their \"Pho\" for a comforting bowl of noodle soup, and the \"Spring Rolls\" are a perfect   \n",
       "appetizer to start your meal. The \"Kung Pao Chicken\" is also a crowd favorite, packed with flavor and a bit of     \n",
       "spice.                                                                                                             \n",
       "\n",
       "Lang Van is a great choice for a delightful dining experience tonight! Enjoy!                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# since llama-index chat is stateful, you should create another instance if there is a change in context\n",
    "li_agent = client.make_agent(llm=gpt_llm, system_prompt = \"sys_prompt\")\n",
    "\n",
    "# context: user3 in Charlotte\n",
    "with client.set_context({\"user_id\":\"user3\", \"location\":\"Charlotte, NC\"}):\n",
    "    print_md(li_agent.chat(\"suggest a restaurant for tonight and tell me why you suggest it\").response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Tecton prompts are used to incorporate real-time, streaming and batch features into your generative AI applications, providing a great solution for personalization. In general, it can be used to provide up to date context for any LLM driven function and ut provides seamless integration with LangChain and LlamaIndex. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tecton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
